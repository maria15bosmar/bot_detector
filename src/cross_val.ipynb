{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import os, sys\n",
    "PATH = os.path.abspath(\"\")[:-3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[245, False, 26735, 99, 20170, 134, 6313, 5.049019607843137, 16.11764705882353, 353.62745098039215, 0.8627450980392157, 0.1568627450980392, 26636]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\maria\\Documents\\Uni\\ia orgs\\bot_detector\\.venv\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:528: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# SCRAPPEAR UN USUARIO\n",
    "from test_user import get_user_data\n",
    "\n",
    "USER = \"ComicGirlAshley\"\n",
    "user_data = get_user_data(USER)\n",
    "print(user_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   factor_rep  verified  followersCount  friendsCount  tweetsCount  \\\n",
      "0         298         0            1637          2062          943   \n",
      "1         222         1          455930             0           85   \n",
      "2         279         0             175           608         1986   \n",
      "3         193         0             660          3301          504   \n",
      "4         775         0            6923          6107         1236   \n",
      "\n",
      "   listedCount  mediaCount  avg_reply  avg_retweet  like_reply  avg_quote  \\\n",
      "0            5         115   0.520833     1.625000   22.604167   0.145833   \n",
      "1         7649          83   0.000000     2.560000   19.560000   0.280000   \n",
      "2            0          57   0.340000     0.100000    1.000000   0.020000   \n",
      "3            0          36   1.921053     0.105263    4.105263   0.026316   \n",
      "4           35        1012   0.096154     0.538462    0.711538   0.038462   \n",
      "\n",
      "   hora_rep  followers_diff  clase  \n",
      "0  0.187500           -1637    bot  \n",
      "1  0.200000         -455929  human  \n",
      "2  0.180000            -175  human  \n",
      "3  0.236842            -660    bot  \n",
      "4  0.211538           -6923    bot  \n"
     ]
    }
   ],
   "source": [
    "# Se leen los datos generados con model.py\\n\",\n",
    "df_data = pd.read_csv(PATH + \"data/training_new.csv\").sample(frac=1).reset_index(drop=True)\n",
    "data = df_data.iloc[:, 1:]\n",
    "print(data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "header_names = list(data.columns.values)\n",
    "for col in data.iloc[:,:-1]:\n",
    "    data[col] = preprocessing.MinMaxScaler().fit_transform(np.array(data[col]).reshape(-1,1))\n",
    "x_data = data.iloc[:,:-1].to_numpy()\n",
    "y_data = data.iloc[:,-1].to_numpy()\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    x_data, y_data, stratify=y_data, test_size=0.33)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['bot' 'bot' 'bot' 'human' 'human']\n",
      "[[0 1]\n",
      " [0 1]\n",
      " [0 1]\n",
      " [1 0]\n",
      " [1 0]]\n"
     ]
    }
   ],
   "source": [
    "#CONVERTIRLA SALIDA A UN VECTOR DE 0 Y 1\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "\n",
    "encoder=LabelBinarizer()\n",
    "label = encoder.fit_transform(y_train)\n",
    "y_train_transformed = np.hstack((label, 1 - label))\n",
    "label = encoder.fit_transform(y_test)\n",
    "y_test_transformed = np.hstack((label, 1 - label))\n",
    "print(y_train[:5])\n",
    "print(y_train_transformed[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "(1616, 13)\n",
      "(1616,)\n",
      "(1616, 2)\n",
      "(796, 13)\n",
      "(796,)\n",
      "(796, 2)\n"
     ]
    }
   ],
   "source": [
    "# COMPROBAR TIPO DE LOS DATOS\n",
    "print(type(x_train))\n",
    "print(type(y_train_transformed))\n",
    "# COMPROBAR DIMENSIONES DE LOS DATOS\n",
    "print(x_train.shape)\n",
    "print(y_train.shape)\n",
    "print(y_train_transformed.shape)\n",
    "print(x_test.shape)\n",
    "print(y_test.shape)\n",
    "print(y_test_transformed.shape) \n",
    "# OBTENER DIMENSION DE LA ENTRADA Y NÚMERO DE SALIDAS\n",
    "input_shape = (x_train.shape[1] ,)\n",
    "num_clases = y_test_transformed.shape[1]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Buscar modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>MLPClassifier(alpha=1e-05, hidden_layer_sizes=(20, 20), random_state=1,\n",
       "              solver=&#x27;lbfgs&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MLPClassifier</label><div class=\"sk-toggleable__content\"><pre>MLPClassifier(alpha=1e-05, hidden_layer_sizes=(20, 20), random_state=1,\n",
       "              solver=&#x27;lbfgs&#x27;)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "MLPClassifier(alpha=1e-05, hidden_layer_sizes=(20, 20), random_state=1,\n",
       "              solver='lbfgs')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "clf = MLPClassifier(solver='lbfgs', alpha=1e-5, \n",
    "    hidden_layer_sizes=(20, 20), random_state=1)\n",
    "\n",
    "clf.fit(x_train, y_train)\n",
    "MLPClassifier(alpha=1e-05, hidden_layer_sizes=(20, 20), random_state=1,\n",
    "              solver='lbfgs')\n",
    "clf.predict([[2., 2.], [-1., -2.]])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_28\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_84 (Dense)            (None, 20)                280       \n",
      "                                                                 \n",
      " dense_85 (Dense)            (None, 20)                420       \n",
      "                                                                 \n",
      " dense_86 (Dense)            (None, 2)                 42        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 742\n",
      "Trainable params: 742\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "101/101 [==============================] - 0s 1ms/step - loss: 0.2122 - accuracy: 0.6906 - mse: 0.2122\n",
      "Epoch 2/20\n",
      "101/101 [==============================] - 0s 1ms/step - loss: 0.1946 - accuracy: 0.7073 - mse: 0.1946\n",
      "Epoch 3/20\n",
      "101/101 [==============================] - 0s 1ms/step - loss: 0.1931 - accuracy: 0.7024 - mse: 0.1931\n",
      "Epoch 4/20\n",
      "101/101 [==============================] - 0s 1ms/step - loss: 0.1924 - accuracy: 0.7017 - mse: 0.1924\n",
      "Epoch 5/20\n",
      "101/101 [==============================] - 0s 1ms/step - loss: 0.1919 - accuracy: 0.7042 - mse: 0.1919\n",
      "Epoch 6/20\n",
      "101/101 [==============================] - 0s 1ms/step - loss: 0.1915 - accuracy: 0.7042 - mse: 0.1915\n",
      "Epoch 7/20\n",
      "101/101 [==============================] - 0s 1ms/step - loss: 0.1912 - accuracy: 0.7036 - mse: 0.1912\n",
      "Epoch 8/20\n",
      "101/101 [==============================] - 0s 1ms/step - loss: 0.1908 - accuracy: 0.7030 - mse: 0.1908\n",
      "Epoch 9/20\n",
      "101/101 [==============================] - 0s 1ms/step - loss: 0.1905 - accuracy: 0.7048 - mse: 0.1905\n",
      "Epoch 10/20\n",
      "101/101 [==============================] - 0s 1ms/step - loss: 0.1902 - accuracy: 0.7048 - mse: 0.1902\n",
      "Epoch 11/20\n",
      "101/101 [==============================] - 0s 1ms/step - loss: 0.1900 - accuracy: 0.7054 - mse: 0.1900\n",
      "Epoch 12/20\n",
      "101/101 [==============================] - 0s 1ms/step - loss: 0.1897 - accuracy: 0.7048 - mse: 0.1897\n",
      "Epoch 13/20\n",
      "101/101 [==============================] - 0s 1ms/step - loss: 0.1895 - accuracy: 0.7054 - mse: 0.1895\n",
      "Epoch 14/20\n",
      "101/101 [==============================] - 0s 1ms/step - loss: 0.1894 - accuracy: 0.7061 - mse: 0.1894\n",
      "Epoch 15/20\n",
      "101/101 [==============================] - 0s 1ms/step - loss: 0.1892 - accuracy: 0.7061 - mse: 0.1892\n",
      "Epoch 16/20\n",
      "101/101 [==============================] - 0s 1ms/step - loss: 0.1891 - accuracy: 0.7061 - mse: 0.1891\n",
      "Epoch 17/20\n",
      "101/101 [==============================] - 0s 1ms/step - loss: 0.1889 - accuracy: 0.7073 - mse: 0.1889\n",
      "Epoch 18/20\n",
      "101/101 [==============================] - 0s 1ms/step - loss: 0.1888 - accuracy: 0.7061 - mse: 0.1888\n",
      "Epoch 19/20\n",
      "101/101 [==============================] - 0s 1ms/step - loss: 0.1887 - accuracy: 0.7054 - mse: 0.1887\n",
      "Epoch 20/20\n",
      "101/101 [==============================] - 0s 1ms/step - loss: 0.1885 - accuracy: 0.7048 - mse: 0.1885\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "input_shape= (x_train.shape[1] ,)\n",
    "final_model = Sequential()\n",
    "arch = [20, 20, 0, \"relu\", 0.2]\n",
    "final_model.add(Dense(arch[0], input_shape=input_shape, activation=arch[3]))\n",
    "final_model.add(Dense(arch[1], input_shape=input_shape, activation=arch[3]))\n",
    "final_model.add(Dense(2, activation='softmax'))\n",
    "final_model.summary()\n",
    "\n",
    "# CONFIGURAR MODELO Y ENTRENAMIENTO\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "epochs = 20\n",
    "final_model.compile(optimizer=tf.keras.optimizers.SGD(learning_rate=arch[4], momentum=0), metrics=['accuracy','mse'], loss='mean_squared_error')\n",
    "historico = final_model.fit(x_train, y_train_transformed, epochs=epochs, verbose=1, shuffle=False, batch_size=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "51/51 [==============================] - 0s 1ms/step - loss: 0.1852 - accuracy: 0.7036 - mse: 0.1852\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.1885 - accuracy: 0.6960 - mse: 0.1885\n",
      "Train results-Loss: 0.18516811728477478 -Accuracy: 0.7035890817642212 -MSE: 0.18516811728477478\n",
      "Test results-Loss: 0.1885344386100769 -Accuracy: 0.69597989320755 -MSE: 0.1885344386100769\n"
     ]
    }
   ],
   "source": [
    "# EVALUAR MODELO DEFINITIVO\n",
    "train_results = final_model.evaluate(x_train, y_train_transformed, verbose=1)\n",
    "test_results= final_model.evaluate(x_test, y_test_transformed, verbose=1)\n",
    "#EL INDICE 0 ES EL LOSS. EL RESTO, LAS MÉTRICAS QUE SE HAN ESPECIFICADO AL COMPILAR EL MODELO.\n",
    "# #EN ESTE CASO 'accuracy':1,'mse':2\n",
    "print(f'Train results-Loss: {train_results[0]} -Accuracy: {train_results[1]} -MSE: {train_results[2]}')\n",
    "print(f'Test results-Loss: {test_results[0]} -Accuracy: {test_results[1]} -MSE: {test_results[2]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/25 [==============================] - 0s 1ms/step\n",
      "[[0.36264595 0.6373541 ]\n",
      " [0.91705054 0.08294941]\n",
      " [0.38812006 0.61187994]\n",
      " [0.42710605 0.572894  ]\n",
      " [0.36394072 0.6360593 ]]\n",
      "['human' 'bot' 'human' 'human' 'human']\n"
     ]
    }
   ],
   "source": [
    "# PREDICCIONES DE LAS CLASES\n",
    "# PREDICCIONES EN BRUTO\n",
    "raw_testPred= final_model.predict(x_test)\n",
    "print(raw_testPred[:5])\n",
    "\n",
    "# PREDICCIONES DE LA CLASE\n",
    "testPred= np.argmax(raw_testPred, axis=1)\n",
    "#TRANSFORMAR EL NÚMERO DE COLUMNA EN LA ETIQUETA\n",
    "class_testPred= encoder.classes_[testPred]\n",
    "print(class_testPred[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['human' 'bot' 'human' 'human' 'human' 'human']\n",
      "['bot' 'human' 'human' 'human' 'human' 'bot']\n",
      "  predicción valor real\n",
      "0      human        bot\n",
      "1        bot      human\n",
      "2      human      human\n",
      "3      human      human\n",
      "4      human      human\n",
      "5      human        bot\n",
      "6      human      human\n",
      "7      human        bot\n",
      "8        bot      human\n",
      "9      human        bot\n"
     ]
    }
   ],
   "source": [
    "test_targets = y_test\n",
    "print(class_testPred[:6])\n",
    "print(test_targets[:6])\n",
    "comp_df = pd.DataFrame({\"predicción\": class_testPred, 'valor real': test_targets}, columns=['predicción','valor real'])\n",
    "#guardar en fichero las salidas de test y target\n",
    "comp_df.to_csv(PATH + 'data/output/salidas_test.csv', index=False)\n",
    "#mostrar 10 primeras filas\n",
    "print(comp_df.iloc[:10,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matriz de confusión\n",
      "[[ 20 444]\n",
      " [110 222]]\n",
      "Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         bot       0.15      0.04      0.07       464\n",
      "       human       0.33      0.67      0.44       332\n",
      "\n",
      "    accuracy                           0.30       796\n",
      "   macro avg       0.24      0.36      0.26       796\n",
      "weighted avg       0.23      0.30      0.22       796\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# MATRIZ DE CONFUSIÓN\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "cm=confusion_matrix(y_test,class_testPred)\n",
    "print('Matriz de confusión')\n",
    "print(cm)\n",
    "print('Classification Report')\n",
    "print(classification_report(y_test,class_testPred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e8d24b60153e914bfadbc0d5c382c116391f93a7ba6cc3a1d5bcf7201918ae2d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
