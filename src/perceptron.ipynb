{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import os, sys\n",
    "PATH = os.path.abspath(\"\")[:-3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[340, False, 26626, 97, 19968, 134, 6255, 4.637254901960785, 17.470588235294116, 271.45098039215685, 0.8921568627450981, 0.1568627450980392, 26529]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\maria\\Documents\\Uni\\ia orgs\\bot_detector\\.venv\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:528: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# SCRAPPEAR UN USUARIO\n",
    "from test_user import get_user_data\n",
    "\n",
    "USER = \"ComicGirlAshley\"\n",
    "user_data = get_user_data(USER)\n",
    "print(user_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   factor_rep  verified  followersCount  friendsCount  tweetsCount  \\\n",
      "0         822         0             387           401         1349   \n",
      "1         256         1          279018          6918        90603   \n",
      "2         628         1          734610           435        22071   \n",
      "3         324         0             184           332         1157   \n",
      "4         196         1          131878          2269          260   \n",
      "\n",
      "   listedCount  mediaCount  avg_reply  avg_retweet   like_reply  avg_quote  \\\n",
      "0            0         825   0.081081     0.729730     2.648649   0.054054   \n",
      "1         1117        6146  49.254902   343.058824  1113.313725  17.156863   \n",
      "2         9121        7977   1.352941    18.372549    38.941176   2.549020   \n",
      "3            3           5   0.615385     0.192308     5.076923   0.115385   \n",
      "4         3402        1785   1.365385     0.192308     3.634615   0.019231   \n",
      "\n",
      "   hora_rep  followers_diff  clase  \n",
      "0  0.243243            -387    bot  \n",
      "1  0.156863         -279017  human  \n",
      "2  0.156863         -734609  human  \n",
      "3  0.173077            -184    bot  \n",
      "4  0.153846         -131877  human  \n"
     ]
    }
   ],
   "source": [
    "# Se leen los datos generados con model.py\\n\",\n",
    "df_data = pd.read_csv(PATH + \"data/training_new.csv\").sample(frac=1).reset_index(drop=True)\n",
    "data = df_data.iloc[:, 1:]\n",
    "print(data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "header_names = list(data.columns.values)\n",
    "for col in data.iloc[:,:-1]:\n",
    "    data[col] = preprocessing.MinMaxScaler().fit_transform(np.array(data[col]).reshape(-1,1))\n",
    "x_data = data.iloc[:,:-1].to_numpy()\n",
    "y_data = data.iloc[:,-1].to_numpy()\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    x_data, y_data, stratify=y_data, test_size=0.33)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['human' 'bot' 'human' 'bot' 'bot']\n",
      "[[1 0]\n",
      " [0 1]\n",
      " [1 0]\n",
      " [0 1]\n",
      " [0 1]]\n"
     ]
    }
   ],
   "source": [
    "#CONVERTIRLA SALIDA A UN VECTOR DE 0 Y 1\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "\n",
    "encoder=LabelBinarizer()\n",
    "label = encoder.fit_transform(y_train)\n",
    "y_train_transformed = np.hstack((label, 1 - label))\n",
    "label = encoder.fit_transform(y_test)\n",
    "y_test_transformed = np.hstack((label, 1 - label))\n",
    "print(y_train[:5])\n",
    "print(y_train_transformed[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "(1616, 13)\n",
      "(1616,)\n",
      "(1616, 2)\n",
      "(796, 13)\n",
      "(796,)\n",
      "(796, 2)\n"
     ]
    }
   ],
   "source": [
    "# COMPROBAR TIPO DE LOS DATOS\n",
    "print(type(x_train))\n",
    "print(type(y_train_transformed))\n",
    "# COMPROBAR DIMENSIONES DE LOS DATOS\n",
    "print(x_train.shape)\n",
    "print(y_train.shape)\n",
    "print(y_train_transformed.shape)\n",
    "print(x_test.shape)\n",
    "print(y_test.shape)\n",
    "print(y_test_transformed.shape) \n",
    "# OBTENER DIMENSION DE LA ENTRADA Y NÚMERO DE SALIDAS\n",
    "input_shape = (x_train.shape[1] ,)\n",
    "num_clases = y_test_transformed.shape[1]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Buscar modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_24\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_72 (Dense)            (None, 50)                700       \n",
      "                                                                 \n",
      " dense_73 (Dense)            (None, 100)               5100      \n",
      "                                                                 \n",
      " dense_74 (Dense)            (None, 2)                 202       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 6,002\n",
      "Trainable params: 6,002\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Crear modelo usando sigmoide\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "input_shape= (x_train.shape[1] ,)\n",
    "model = Sequential()\n",
    "arch = [50, 100, 0, \"relu\", 0.2]\n",
    "model.add(Dense(arch[0], input_shape=input_shape, activation=arch[3]))\n",
    "if arch[1] != 0:\n",
    "    model.add(Dense(arch[1], input_shape=input_shape, activation=arch[3]))\n",
    "if arch[2] != 0:\n",
    "    model.add(Dense(arch[2], input_shape=input_shape, activation=arch[3]))\n",
    "model.add(Dense(2, activation='softmax'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3000\n",
      "81/81 [==============================] - 1s 3ms/step - loss: 0.2137 - accuracy: 0.6943 - mse: 0.2137 - val_loss: 0.1986 - val_accuracy: 0.6914 - val_mse: 0.1986\n",
      "Epoch 2/3000\n",
      "81/81 [==============================] - 0s 2ms/step - loss: 0.1938 - accuracy: 0.7128 - mse: 0.1938 - val_loss: 0.1928 - val_accuracy: 0.6914 - val_mse: 0.1928\n",
      "Epoch 3/3000\n",
      "81/81 [==============================] - 0s 2ms/step - loss: 0.1918 - accuracy: 0.7113 - mse: 0.1918 - val_loss: 0.1917 - val_accuracy: 0.6914 - val_mse: 0.1917\n",
      "Epoch 4/3000\n",
      "81/81 [==============================] - 0s 2ms/step - loss: 0.1911 - accuracy: 0.7098 - mse: 0.1911 - val_loss: 0.1912 - val_accuracy: 0.6914 - val_mse: 0.1912\n",
      "Epoch 5/3000\n",
      "81/81 [==============================] - 0s 2ms/step - loss: 0.1906 - accuracy: 0.7090 - mse: 0.1906 - val_loss: 0.1907 - val_accuracy: 0.6914 - val_mse: 0.1907\n",
      "Epoch 6/3000\n",
      "81/81 [==============================] - 0s 2ms/step - loss: 0.1902 - accuracy: 0.7098 - mse: 0.1902 - val_loss: 0.1904 - val_accuracy: 0.6914 - val_mse: 0.1904\n",
      "Epoch 7/3000\n",
      "81/81 [==============================] - 0s 2ms/step - loss: 0.1898 - accuracy: 0.7105 - mse: 0.1898 - val_loss: 0.1903 - val_accuracy: 0.6914 - val_mse: 0.1903\n",
      "Epoch 8/3000\n",
      "81/81 [==============================] - 0s 2ms/step - loss: 0.1896 - accuracy: 0.7105 - mse: 0.1896 - val_loss: 0.1901 - val_accuracy: 0.6914 - val_mse: 0.1901\n",
      "Epoch 9/3000\n",
      "81/81 [==============================] - 0s 2ms/step - loss: 0.1893 - accuracy: 0.7090 - mse: 0.1893 - val_loss: 0.1901 - val_accuracy: 0.6914 - val_mse: 0.1901\n",
      "Epoch 10/3000\n",
      "81/81 [==============================] - 0s 2ms/step - loss: 0.1890 - accuracy: 0.7082 - mse: 0.1890 - val_loss: 0.1899 - val_accuracy: 0.6914 - val_mse: 0.1899\n",
      "Epoch 11/3000\n",
      "81/81 [==============================] - 0s 2ms/step - loss: 0.1888 - accuracy: 0.7098 - mse: 0.1888 - val_loss: 0.1899 - val_accuracy: 0.6914 - val_mse: 0.1899\n",
      "Epoch 12/3000\n",
      "81/81 [==============================] - 0s 2ms/step - loss: 0.1886 - accuracy: 0.7090 - mse: 0.1886 - val_loss: 0.1899 - val_accuracy: 0.6914 - val_mse: 0.1899\n"
     ]
    }
   ],
   "source": [
    "# CONFIGURAR MODELO Y ENTRENAMIENTO\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "epochs = 3000\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=1)\n",
    "model.compile(optimizer=tf.keras.optimizers.SGD(learning_rate=arch[4], momentum=0), metrics=['accuracy','mse'], loss='mean_squared_error')\n",
    "historico = model.fit(x_train, y_train_transformed, epochs=epochs, verbose=1, validation_split=0.2,\n",
    "    shuffle=False, validation_freq=1, batch_size=16, callbacks=[early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11\n",
      "0.18882940709590912\n",
      "0.18987923860549927\n",
      "0.7097523212432861\n",
      "0.6913580298423767\n"
     ]
    }
   ],
   "source": [
    "col_names = ['arquitectura', 'loss', 'val_loss', 'accuracy', 'val_accuracy', 'epoch']\n",
    "#dff = pd.DataFrame([], columns=col_names)\n",
    "dff = pd.read_csv(PATH + 'data/output/vals2.csv')\n",
    "final_epoch=len(historico.history['loss'])-1\n",
    "print(final_epoch)\n",
    "tloss = historico.history['loss'][final_epoch-1]\n",
    "print(tloss)\n",
    "vloss = historico.history['val_loss'][final_epoch-1]\n",
    "print(vloss)\n",
    "tacc = historico.history['accuracy'][final_epoch-1]\n",
    "print(tacc)\n",
    "vacc = historico.history['val_accuracy'][final_epoch-1]\n",
    "print(vacc)\n",
    "datos = pd.DataFrame([[arch, tloss, vloss, tacc, vacc, final_epoch]], columns=col_names)\n",
    "datos = pd.concat([dff, datos], ignore_index=True)\n",
    "datos.to_csv(PATH + 'data/output/vals2.csv', index = False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_28\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_84 (Dense)            (None, 20)                280       \n",
      "                                                                 \n",
      " dense_85 (Dense)            (None, 20)                420       \n",
      "                                                                 \n",
      " dense_86 (Dense)            (None, 2)                 42        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 742\n",
      "Trainable params: 742\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "101/101 [==============================] - 0s 1ms/step - loss: 0.2122 - accuracy: 0.6906 - mse: 0.2122\n",
      "Epoch 2/20\n",
      "101/101 [==============================] - 0s 1ms/step - loss: 0.1946 - accuracy: 0.7073 - mse: 0.1946\n",
      "Epoch 3/20\n",
      "101/101 [==============================] - 0s 1ms/step - loss: 0.1931 - accuracy: 0.7024 - mse: 0.1931\n",
      "Epoch 4/20\n",
      "101/101 [==============================] - 0s 1ms/step - loss: 0.1924 - accuracy: 0.7017 - mse: 0.1924\n",
      "Epoch 5/20\n",
      "101/101 [==============================] - 0s 1ms/step - loss: 0.1919 - accuracy: 0.7042 - mse: 0.1919\n",
      "Epoch 6/20\n",
      "101/101 [==============================] - 0s 1ms/step - loss: 0.1915 - accuracy: 0.7042 - mse: 0.1915\n",
      "Epoch 7/20\n",
      "101/101 [==============================] - 0s 1ms/step - loss: 0.1912 - accuracy: 0.7036 - mse: 0.1912\n",
      "Epoch 8/20\n",
      "101/101 [==============================] - 0s 1ms/step - loss: 0.1908 - accuracy: 0.7030 - mse: 0.1908\n",
      "Epoch 9/20\n",
      "101/101 [==============================] - 0s 1ms/step - loss: 0.1905 - accuracy: 0.7048 - mse: 0.1905\n",
      "Epoch 10/20\n",
      "101/101 [==============================] - 0s 1ms/step - loss: 0.1902 - accuracy: 0.7048 - mse: 0.1902\n",
      "Epoch 11/20\n",
      "101/101 [==============================] - 0s 1ms/step - loss: 0.1900 - accuracy: 0.7054 - mse: 0.1900\n",
      "Epoch 12/20\n",
      "101/101 [==============================] - 0s 1ms/step - loss: 0.1897 - accuracy: 0.7048 - mse: 0.1897\n",
      "Epoch 13/20\n",
      "101/101 [==============================] - 0s 1ms/step - loss: 0.1895 - accuracy: 0.7054 - mse: 0.1895\n",
      "Epoch 14/20\n",
      "101/101 [==============================] - 0s 1ms/step - loss: 0.1894 - accuracy: 0.7061 - mse: 0.1894\n",
      "Epoch 15/20\n",
      "101/101 [==============================] - 0s 1ms/step - loss: 0.1892 - accuracy: 0.7061 - mse: 0.1892\n",
      "Epoch 16/20\n",
      "101/101 [==============================] - 0s 1ms/step - loss: 0.1891 - accuracy: 0.7061 - mse: 0.1891\n",
      "Epoch 17/20\n",
      "101/101 [==============================] - 0s 1ms/step - loss: 0.1889 - accuracy: 0.7073 - mse: 0.1889\n",
      "Epoch 18/20\n",
      "101/101 [==============================] - 0s 1ms/step - loss: 0.1888 - accuracy: 0.7061 - mse: 0.1888\n",
      "Epoch 19/20\n",
      "101/101 [==============================] - 0s 1ms/step - loss: 0.1887 - accuracy: 0.7054 - mse: 0.1887\n",
      "Epoch 20/20\n",
      "101/101 [==============================] - 0s 1ms/step - loss: 0.1885 - accuracy: 0.7048 - mse: 0.1885\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "input_shape= (x_train.shape[1] ,)\n",
    "final_model = Sequential()\n",
    "arch = [20, 20, 0, \"relu\", 0.2]\n",
    "final_model.add(Dense(arch[0], input_shape=input_shape, activation=arch[3]))\n",
    "final_model.add(Dense(arch[1], input_shape=input_shape, activation=arch[3]))\n",
    "final_model.add(Dense(2, activation='softmax'))\n",
    "final_model.summary()\n",
    "\n",
    "# CONFIGURAR MODELO Y ENTRENAMIENTO\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "epochs = 20\n",
    "final_model.compile(optimizer=tf.keras.optimizers.SGD(learning_rate=arch[4], momentum=0), metrics=['accuracy','mse'], loss='mean_squared_error')\n",
    "historico = final_model.fit(x_train, y_train_transformed, epochs=epochs, verbose=1, shuffle=False, batch_size=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "51/51 [==============================] - 0s 1ms/step - loss: 0.1852 - accuracy: 0.7036 - mse: 0.1852\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.1885 - accuracy: 0.6960 - mse: 0.1885\n",
      "Train results-Loss: 0.18516811728477478 -Accuracy: 0.7035890817642212 -MSE: 0.18516811728477478\n",
      "Test results-Loss: 0.1885344386100769 -Accuracy: 0.69597989320755 -MSE: 0.1885344386100769\n"
     ]
    }
   ],
   "source": [
    "# EVALUAR MODELO DEFINITIVO\n",
    "train_results = final_model.evaluate(x_train, y_train_transformed, verbose=1)\n",
    "test_results= final_model.evaluate(x_test, y_test_transformed, verbose=1)\n",
    "#EL INDICE 0 ES EL LOSS. EL RESTO, LAS MÉTRICAS QUE SE HAN ESPECIFICADO AL COMPILAR EL MODELO.\n",
    "# #EN ESTE CASO 'accuracy':1,'mse':2\n",
    "print(f'Train results-Loss: {train_results[0]} -Accuracy: {train_results[1]} -MSE: {train_results[2]}')\n",
    "print(f'Test results-Loss: {test_results[0]} -Accuracy: {test_results[1]} -MSE: {test_results[2]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/25 [==============================] - 0s 1ms/step\n",
      "[[0.36264595 0.6373541 ]\n",
      " [0.91705054 0.08294941]\n",
      " [0.38812006 0.61187994]\n",
      " [0.42710605 0.572894  ]\n",
      " [0.36394072 0.6360593 ]]\n",
      "['human' 'bot' 'human' 'human' 'human']\n"
     ]
    }
   ],
   "source": [
    "# PREDICCIONES DE LAS CLASES\n",
    "# PREDICCIONES EN BRUTO\n",
    "raw_testPred= final_model.predict(x_test)\n",
    "print(raw_testPred[:5])\n",
    "\n",
    "# PREDICCIONES DE LA CLASE\n",
    "testPred= np.argmax(raw_testPred, axis=1)\n",
    "#TRANSFORMAR EL NÚMERO DE COLUMNA EN LA ETIQUETA\n",
    "class_testPred= encoder.classes_[testPred]\n",
    "print(class_testPred[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['human' 'bot' 'human' 'human' 'human' 'human']\n",
      "['bot' 'human' 'human' 'human' 'human' 'bot']\n",
      "  predicción valor real\n",
      "0      human        bot\n",
      "1        bot      human\n",
      "2      human      human\n",
      "3      human      human\n",
      "4      human      human\n",
      "5      human        bot\n",
      "6      human      human\n",
      "7      human        bot\n",
      "8        bot      human\n",
      "9      human        bot\n"
     ]
    }
   ],
   "source": [
    "test_targets = y_test\n",
    "print(class_testPred[:6])\n",
    "print(test_targets[:6])\n",
    "comp_df = pd.DataFrame({\"predicción\": class_testPred, 'valor real': test_targets}, columns=['predicción','valor real'])\n",
    "#guardar en fichero las salidas de test y target\n",
    "comp_df.to_csv(PATH + 'data/output/salidas_test.csv', index=False)\n",
    "#mostrar 10 primeras filas\n",
    "print(comp_df.iloc[:10,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matriz de confusión\n",
      "[[ 20 444]\n",
      " [110 222]]\n",
      "Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         bot       0.15      0.04      0.07       464\n",
      "       human       0.33      0.67      0.44       332\n",
      "\n",
      "    accuracy                           0.30       796\n",
      "   macro avg       0.24      0.36      0.26       796\n",
      "weighted avg       0.23      0.30      0.22       796\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# MATRIZ DE CONFUSIÓN\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "cm=confusion_matrix(y_test,class_testPred)\n",
    "print('Matriz de confusión')\n",
    "print(cm)\n",
    "print('Classification Report')\n",
    "print(classification_report(y_test,class_testPred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e8d24b60153e914bfadbc0d5c382c116391f93a7ba6cc3a1d5bcf7201918ae2d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
